# Secondary Persona: James Rodriguez - Engineering Team Lead

## Basic Information

- **Name**: James Rodriguez
- **Age**: 38
- **Role**: Engineering Team Lead at a fast-growing startup
- **Location**: Austin, TX
- **Education**: BS in Software Engineering, MBA (part-time, in progress)

## Background

### Professional Background

James has 14 years of software engineering experience and has been leading engineering teams for the past 5 years. He's currently managing a team of 8 developers at a Series B startup building a B2B SaaS platform.

His team recently started using AI coding assistants (mix of Cursor and Windsurf) to boost productivity. James is looking for ways to standardize their development process and ensure consistent quality across the team, especially as they scale.

### Technical Proficiency

- **Expert**: JavaScript/TypeScript, Node.js, React, PostgreSQL, team leadership
- **Advanced**: AWS, CI/CD pipelines, Docker, API design
- **Intermediate**: Python, AI coding tools (Cursor, Windsurf), GitHub Actions
- **Learning**: MCP protocol, AI-powered development workflows, agent orchestration

### Relevant Experience

- Led teams through 3 product launches
- Implemented and refined agile development processes
- Introduced code review and testing standards
- Recently adopted AI coding assistants across team
- Balances technical work (30%) with team leadership (70%)

## Goals & Motivations

### Primary Goals

1. **Increase team velocity** while maintaining code quality
2. **Standardize development practices** across all team members
3. **Scale team effectively** without sacrificing quality or burning out developers
4. **Leverage AI tools** to eliminate repetitive work and focus on hard problems
5. **Reduce onboarding time** for new hires

### What Success Looks Like

- Team ships features 30-40% faster with AI assistance
- Consistent code quality across all developers (junior to senior)
- New hires productive within 2 weeks instead of 6 weeks
- Developers spend more time on creative problem-solving, less on boilerplate
- Documentation and testing are always up to standard

### Key Motivations

- **Team Success**: Seeing his developers grow and deliver great work
- **Business Impact**: Hitting product milestones and company OKRs
- **Work-Life Balance**: Sustainable pace for team, avoiding crunch and burnout
- **Professional Reputation**: Known for building high-performing, happy teams

## Pain Points & Frustrations

### Current Challenges

1. **Inconsistent AI Tool Usage**: "Half my team uses Cursor, half uses Windsurf. They each have different workflows and we end up with inconsistent practices."

2. **Lack of Development Standards**: "AI tools are powerful but they don't enforce our development process. Each developer approaches tasks differently."

3. **Quality Varies**: "Senior devs produce great code with AI help, but junior devs sometimes skip important steps like writing tests or security considerations."

4. **Platform Lock-in Concerns**: "If we standardize on Cursor's rules, what happens if we want to switch tools later? I don't want vendor lock-in."

5. **Onboarding Complexity**: "New hires need to learn our codebase, our processes, AND how to use whatever AI tool they prefer. It's a lot."

6. **Documentation Gaps**: "AI can write code fast, but developers forget to document their decisions and maintain project docs."

### Frustrations with Existing Solutions

- **Claude Code Skills**: "Looks great but we're not all using Claude Code. Can't force everyone to switch."
- **Cursor Rules**: "Works for Cursor users but not portable. What about Windsurf users?"
- **Manual Process Docs**: "We have a wiki but developers don't always follow it. Need something enforced by the AI itself."
- **Framework Learning Curve**: "LangChain looks powerful but would require dedicated time to learn and integrate. We need something simpler."

## Behaviors & Preferences

### How He Currently Solves the Problem

- Created a team wiki with development guidelines
- Weekly team code reviews to catch quality issues
- Pair programming for junior developers
- Trying to document best practices in README files
- Experimenting with different AI tool configurations

### Preferred Tools and Platforms

- **Team Collaboration**: Slack, Linear, GitHub, Figma
- **AI Coding**: Team uses mix of Cursor and Windsurf
- **Development**: VS Code, GitHub, Vercel, AWS
- **Learning**: Tech Twitter, newsletter subscriptions, podcasts during commute

### Usage Patterns

- Reviews team's PRs daily (1-2 hours)
- Weekly 1:1s with each team member
- Checks team velocity and sprint progress every few days
- Evaluates new tools monthly, adopts quarterly
- Values tools that work out of the box with minimal setup
- Prefers solutions that don't require extensive training

### Communication Preferences

- Slack for day-to-day team communication
- Video calls for complex discussions or 1:1s
- GitHub PRs for code review discussions
- Documentation: Executive summary first, details available if needed
- Prefers visual aids (diagrams, screenshots) over walls of text

## Needs from This Product

### Must-Have Features (P0)

1. **Cross-Platform Compatibility**: Works with Cursor, Windsurf, Claude Code, and custom agents
2. **Development Methodology**: Structured workflow from ideation through deployment
3. **Easy Setup**: Team members can start using it within 30 minutes
4. **Consistent Results**: Same methodology regardless of which AI tool someone uses
5. **Quality Built-In**: Code review, testing, documentation baked into the process
6. **Clear Documentation**: Quick start guide that gets team productive fast

### Important Features (P1)

1. **Team Onboarding**: New hires can follow the methodology to get up to speed quickly
2. **Customization**: Ability to add company-specific practices or standards
3. **Visibility**: See which stages/skills the team is using most
4. **Best Practices**: Security, testing, documentation enforced in the workflow
5. **Scalability**: Works for 8 developers now, 20 developers in 6 months
6. **Community Support**: Active project with responsive maintainers
7. **Integration Friendly**: Doesn't conflict with existing tools (GitHub, CI/CD)

### Nice-to-Have Features (P2)

1. **Team Analytics**: Track team velocity and quality metrics
2. **Custom Skills**: Add company-specific workflows
3. **Templates**: Pre-built workflows for common tasks (API endpoint, feature, bug fix)
4. **Training Materials**: Guides for onboarding team members
5. **Slack Integration**: Notifications or updates in team Slack
6. **Progress Tracking**: See which stage each project/feature is in

## Quote

> "I need a development methodology that works regardless of which AI tool my team uses. Something that ensures juniors follow best practices, seniors stay productive, and everyone ships quality code. If it can standardize our workflow across Cursor, Windsurf, and whatever comes next, that would solve a huge problem for us. Bonus if it helps onboard new hires faster."

## User Journey

### Discovery Phase
- Hears about MCP Skills Server from tech Twitter or newsletter
- Reads about it solving platform lock-in and methodology standardization
- Checks if it works with team's current tools (Cursor, Windsurf)
- Reviews examples to see if it fits team's workflow

### Evaluation Phase
- Tests with 2-3 volunteers from the team
- Evaluates if setup is simple enough for whole team
- Checks if methodology aligns with team's existing practices
- Assesses if it improves code quality and consistency
- Gets feedback from testers

### Rollout Phase
- Introduces to team in sprint planning meeting
- Provides setup guide and quick start
- Makes it optional for first sprint
- Gathers feedback and adjusts configuration

### Adoption Phase
- Monitors team adoption and usage
- Celebrates early wins (faster onboarding, better test coverage)
- Iterates based on team feedback
- Makes it the default workflow for new projects
- Uses it as part of onboarding for new hires

## How This Product Solves James's Problems

| Pain Point | How MCP Skills Server Helps |
|------------|----------------------------|
| Inconsistent AI Tool Usage | MCP standard works across Cursor, Windsurf, Claude Code - team can use preferred tool |
| Lack of Development Standards | Dev-swarms provides structured 10-stage methodology everyone follows |
| Quality Varies | Code review, testing, security built into the workflow stages |
| Platform Lock-in Concerns | MCP is open standard, not locked to any vendor |
| Onboarding Complexity | New hires follow same structured methodology, learn faster |
| Documentation Gaps | Documentation stage built into workflow (Stage 0, PRD, tech specs, etc.) |
| Team Scalability | Methodology scales - works for 8 developers or 20 developers |

## Differences from Primary Persona (Maya)

While Maya (AI Platform Engineer) needs to **build and integrate** the MCP Skills Server into custom systems, James (Engineering Team Lead) needs to **deploy and adopt** it for his team.

**Maya's Focus**:
- Technical implementation
- Security architecture
- Custom integration
- Platform engineering

**James's Focus**:
- Team productivity
- Ease of adoption
- Cross-tool compatibility
- Workflow standardization

Both personas benefit from the same product but have different success criteria and usage patterns.
